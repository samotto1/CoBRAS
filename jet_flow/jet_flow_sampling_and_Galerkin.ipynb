{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import linalg\n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import linear_operators as lin_ops\n",
    "import boundary_conditions as bcs\n",
    "import time_steppers as tstep\n",
    "import rom_functions as rom\n",
    "\n",
    "import time as tlib\n",
    "\n",
    "\n",
    "plt.rcParams.update({\"text.usetex\":True,\\\n",
    "                     \"font.family\":\"serif\",\\\n",
    "                     \"font.sans-serif\":[\"Computer Modern\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc7e0a3",
   "metadata": {},
   "source": [
    "# Jet flow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd7faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class jet_class:\n",
    "    \n",
    "    def __init__(self,r,z,Re,theta0):\n",
    "        \n",
    "        self.r = r\n",
    "        self.z = z\n",
    "        self.rowsu = len(r) + 2\n",
    "        self.colsu = len(z) + 1\n",
    "        self.szu = self.rowsu*self.colsu\n",
    "        self.rowsv = len(r) + 1\n",
    "        self.colsv = len(z) + 2\n",
    "        self.szv = self.rowsv*self.colsv\n",
    "        self.rowsp = len(r)\n",
    "        self.colsp = len(z)\n",
    "        self.szp = self.rowsp*self.colsp + 1\n",
    "        \n",
    "        self.Re = Re\n",
    "        self.theta0 = theta0\n",
    "        self.q_sbf = 0\n",
    "\n",
    "def assemble_initial_conditions(jet):\n",
    "    \n",
    "    qic = np.zeros(jet.szu + jet.szv)\n",
    "    for i in range (1,jet.rowsu-1):\n",
    "        for j in range (1,jet.colsu):\n",
    "            \n",
    "            k = i*jet.colsu + j\n",
    "            qic[k] = 0.5*(1 - np.tanh((jet.r[i-1] - 1/(4*jet.r[i-1]))/(4*jet.theta0)))\n",
    "    \n",
    "    qic = bcs.update_boundary_conditions(jet.r,jet.z,qic,jet.theta0,1)\n",
    "    return qic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_data(jet,lops,time,nsave,alphas):\n",
    "    # jet & lops:   cfd classes\n",
    "    # q_sbf:        steady base flow\n",
    "    # time:         time vector (this specifies the cfd time stepper)\n",
    "    # nsave:        save data every nsave snapshots\n",
    "    # alphas:       impulse magnitude\n",
    "    \n",
    "    \n",
    "    # Outputs:  x_traj_data with size (see below)\n",
    "    #           t_data = time[::nsave]\n",
    "    \n",
    "    N = lops.Mrem.shape[0]\n",
    "    x_traj_data = np.zeros((len(alphas),N,len(time)//nsave),dtype=np.float64)\n",
    "    for k in range (len(alphas)):\n",
    "        print(\"Simulating trajectory %d/%d with alpha = %1.3e\"%(k+1,len(alphas),alphas[k]))\n",
    "        qic = lops.B*alphas[k] + jet.q_sbf\n",
    "        x, t_data = tstep.nonlinear_solver(jet,lops,time,nsave,qic)\n",
    "        x = lops.Wsqrt.dot(x - jet.q_sbf.reshape((jet.szu+jet.szv,1)))\n",
    "        x_traj_data[k,] = lops.Mrem.dot(x)\n",
    "        \n",
    "    return x_traj_data, t_data\n",
    "\n",
    "\n",
    "def simulate_nonlinear_forward(jet,lops,x_ic,time,nsave,*argv):\n",
    "    q_ic = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(x_ic))) + jet.q_sbf\n",
    "    \n",
    "    if len(argv) == 0:\n",
    "        data_nonlin, tsave_nonlin = tstep.nonlinear_solver(jet,lops,time,nsave,q_ic)\n",
    "    else:\n",
    "        forcing = argv[0]\n",
    "        data_nonlin, tsave_nonlin = tstep.nonlinear_solver(jet,lops,time,nsave,q_ic,forcing)\n",
    "        \n",
    "    data_nonlin = lops.Mrem.dot(lops.Wsqrt.dot(data_nonlin - jet.q_sbf.reshape((-1,1))))\n",
    "    \n",
    "    return data_nonlin, tsave_nonlin\n",
    "\n",
    "\n",
    "def simulate_linear_forward(jet,lops,v_ic,time,nsave,*argv):\n",
    "    # v_ic:         initial condition in \"x\" coordinates x = sqrt(W)(q - q_sbf)\n",
    "    # q_sbf:        this is the q-coordinates steady state (usual thing)\n",
    "    \n",
    "    if len(argv) > 0:       # this lets you linearize about time-varying base flow\n",
    "        xbaseflow = argv[0]\n",
    "        # Take a euclidean vec qic with no boundary points. Transform to weighted\n",
    "        # statespace and add boundaries\n",
    "        qbaseflow = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(xbaseflow))) + jet.q_sbf.reshape((-1,1))\n",
    "        flag = 'ubf'\n",
    "    else:                   # this is linerization about steady base flow\n",
    "        qbaseflow = jet.q_sbf\n",
    "        flag = 'sbf'\n",
    "    \n",
    "    vq_ic = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(v_ic)))\n",
    "    data_lin, tsave_lin = tstep.linear_solver(jet,lops,time,nsave,qbaseflow,vq_ic,flag)\n",
    "    data_lin = lops.Mrem.dot(lops.Wsqrt.dot(data_lin))\n",
    "    \n",
    "    return data_lin, tsave_lin\n",
    "\n",
    "\n",
    "def simulate_linear_adjoint(jet,lops,lam_fc,time,nsave,*argv):\n",
    "    \n",
    "    \n",
    "    if len(argv) > 0:       # this lets you linearize about time-varying base flow\n",
    "        xbaseflow = argv[0]\n",
    "        # Take a euclidean vec qic with no boundary points. Transform to weighted\n",
    "        # statespace and add boundaries\n",
    "        qbaseflow = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(xbaseflow))) + jet.q_sbf.reshape((-1,1))\n",
    "        flag = 'ubf'\n",
    "    else:                   # this is linerization about steady base flow\n",
    "        qbaseflow = jet.q_sbf\n",
    "        flag = 'sbf'\n",
    "    \n",
    "    lam_q_fc = lops.BC_op_T.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(lam_fc)))\n",
    "    data_adj, t_adj = tstep.adjoint_solver(jet,lops,time,nsave,qbaseflow,lam_q_fc,flag)\n",
    "    data_adj = np.fliplr(lops.Mrem.dot(lops.Wsqrt.dot(data_adj)))\n",
    "    \n",
    "    return data_adj, t_adj\n",
    "\n",
    "def assemble_rom(jet,lops,Phi,Psi):\n",
    "    f0_ROM = np.dot(Psi.T, rom.evaluate_f(jet,lops,0.0*Phi[:,0],0.0))\n",
    "    \n",
    "    B_ROM = np.reshape(np.dot(Psi.T, rom.evaluate_f(jet,lops,0.0*Phi[:,0],1.0)) - f0_ROM, (-1,1))\n",
    "    \n",
    "    C_ROM = Phi\n",
    "    \n",
    "    A_ROM = np.zeros((r, r))\n",
    "    for j in range(r):\n",
    "        A_ROM[:,j] = np.dot(Psi.T, rom.evaluate_df(jet,lops,0.0*Phi[:,0],0.0,Phi[:,j]))\n",
    "    \n",
    "    N_ROM = np.zeros((r, 1, r))\n",
    "    \n",
    "    H_ROM = np.zeros((r, r, r))\n",
    "    for i in tqdm(range(r), position=0, leave=True, desc=\"assembling 3rd order tensor\"):\n",
    "        H_ROM[:,i,i] = np.dot(Psi.T, rom.evaluate_f(jet,lops,Phi[:,i],0.0)) - f0_ROM - A_ROM[:,i]\n",
    "        for j in range(1, r):\n",
    "            H_ROM[:,i,j] = np.dot(Psi.T, rom.evaluate_f(jet,lops,Phi[:,i]+Phi[:,j],0.0) \\\n",
    "                              - rom.evaluate_f(jet,lops,Phi[:,i]-Phi[:,j],0.0) )/4.0 - A_ROM[:,j]/2.0\n",
    "            H_ROM[:,j,i] = H_ROM[:,i,j]\n",
    "    \n",
    "    return f0_ROM, A_ROM, B_ROM, C_ROM, H_ROM, N_ROM\n",
    "\n",
    "def output_fields(jet,q):\n",
    "    \n",
    "    u = np.zeros((jet.rowsp+1,jet.colsp+1))\n",
    "    v = u.copy()\n",
    "    w = u.copy()\n",
    "    \n",
    "    dr = jet.r[1] - jet.r[0]\n",
    "    dz = jet.z[1] - jet.z[0]\n",
    "    \n",
    "    r = np.zeros(jet.rowsp+1)\n",
    "    z = np.zeros(jet.colsp+1)\n",
    "    for j in range (jet.rowsp+1): r[j] = j*dr\n",
    "    for j in range (jet.colsp+1): z[j] = j*dz\n",
    "    Z, R = np.meshgrid(z,r)\n",
    "    \n",
    "    for i in range (0,jet.rowsp+1):\n",
    "        for j in range (0,jet.colsp+1):\n",
    "            \n",
    "            ku = i*jet.colsu + j\n",
    "            kv = i*jet.colsv + j + jet.szu\n",
    "            \n",
    "            u[i,j] = 0.5*(q[ku] + q[ku+jet.colsu])\n",
    "            v[i,j] = 0.5*(q[kv] + q[kv+1])\n",
    "            w[i,j] = (q[kv+1] - q[kv])/dz - (q[ku+jet.colsu] - q[ku])/dr\n",
    "            w[i,j] = w[i,j]\n",
    "            \n",
    "    return u, v, w, Z, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea7ac41",
   "metadata": {},
   "source": [
    "## Jet flow parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# --------- Assemble grid ---------------------------\n",
    "# ---------------------------------------------------\n",
    "\n",
    "Lr = 4              # Length of radial direction\n",
    "Nr = 200            # Number of grid points in radial direction\n",
    "dr = Lr/Nr\n",
    "r = np.zeros(Nr)\n",
    "for j in range (0,Nr): r[j] = j*dr + dr/2\n",
    "\n",
    "\n",
    "Lz = 10             # Length of axial direction\n",
    "Nz = 250            # Number of grid points in axial direction\n",
    "dz = Lz/Nz\n",
    "z = np.zeros(Nz)\n",
    "for j in range (0,Nz): z[j] = j*dz + dz/2\n",
    "\n",
    "\n",
    "Re = 2000           # Reynolds number\n",
    "theta0 = 0.025      # non-dimensional thickness of incoming flow \n",
    "\n",
    "\n",
    "r0 = 0.5            # Radial location of center of forcing Gaussian blob\n",
    "z0 = 1.0            # Axial location of center of forcing Gaussian blob\n",
    "direction = 'radial'# The forcing impulse enters the radial momentum equation (can change to 'axial')\n",
    "jet = jet_class(r,z,Re,theta0)  \n",
    "lops = lin_ops.linear_operators_class(jet,r0,z0,direction)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# --------- Specify time horizon --------------------\n",
    "# ---------------------------------------------------\n",
    "dt = 0.005           # dt for simulation\n",
    "n = np.intc(1/dt)    # number of time steps per non-dimensional time unit\n",
    "N = 50*n             # total number of time steps (i.e., tf = dt*N) # 30*n for Re=1000, 50*n for Re=2000\n",
    "time = dt*np.arange(0,N,1)\n",
    "nsave = 100          # save data every nsave snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc1cf9",
   "metadata": {},
   "source": [
    "## Generate base flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qic = assemble_initial_conditions(jet)\n",
    "# data, _ = tstep.nonlinear_solver(jet,lops,time,nsave,qic)\n",
    "# data, _ = tstep.nonlinear_solver(jet,lops,time,nsave,data[:,-1])\n",
    "# data, _ = tstep.nonlinear_solver(jet,lops,time,nsave,q_sbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"steady_state_solution_Re2000_Nr200_Nz250.txt\",data[:,-1])\n",
    "# np.savetxt(\"data/steady_state_solution_Re2000_Nr200_Nz250.txt\", data[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699e6ec",
   "metadata": {},
   "source": [
    "## Load base flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_sbf = np.loadtxt(\"steady_state_solution_Re2000_Nr200_Nz250.txt\") # Load the stable steady state\n",
    "q_sbf = np.loadtxt(\"data/steady_state_solution_Re2000_Nr200_Nz250.txt\")\n",
    "jet.q_sbf = q_sbf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c676033",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c52691",
   "metadata": {},
   "source": [
    "## Impulse-response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.asarray([0.005, 0.02, 0.04, 0.06, 0.08, 0.10]) # training data\n",
    "alphas = np.concatenate((-np.flipud(alphas),alphas))\n",
    "\n",
    "# alphas = np.random.uniform(low=-0.10, high=0.10, size=(25)) # evaluation and testing data\n",
    "\n",
    "x_traj_data, t_data = generate_data(jet,lops,time,nsave,alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b722cf",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71caf061",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/traj_data_train.mat'\n",
    "data = {'alphas': alphas, \\\n",
    "        'x_traj_data': x_traj_data, \\\n",
    "        't_data': t_data, \\\n",
    "        'q_sbf': q_sbf}\n",
    "\n",
    "with open(fname, 'wb') as fh:\n",
    "   pickle.dump(data, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a1210b",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/traj_data_train.mat'\n",
    "\n",
    "with open(fname, 'rb') as fh:\n",
    "   data = pickle.load(fh)\n",
    "\n",
    "alphas = data['alphas']\n",
    "x_traj_data = data['x_traj_data']\n",
    "t_data = data['t_data']\n",
    "n_traj = len(alphas)\n",
    "u_traj = np.zeros((n_traj, 1, len(time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a09fc",
   "metadata": {},
   "source": [
    "## Energy along trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f89791",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "energy = np.zeros((len(alphas),len(t_data)))\n",
    "for k in range (len(alphas)):\n",
    "    for j in range (len(t_data)):\n",
    "        energy[k,j] = np.dot(x_traj_data[k,:,j],x_traj_data[k,:,j])\n",
    "        \n",
    "    plt.plot(t_data, energy[k,],'k')\n",
    "\n",
    "# plt.savefig('../figures/jet_flow/energy_trajectories.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('../figures/jet_flow/energy_trajectories.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c453ddc",
   "metadata": {},
   "source": [
    "## Plot a flowfield snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ab08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add boundary conditions to the flowfield you wanna plot. This flowfield is a perturbation \n",
    "# about the base flow q_sbf\n",
    "\n",
    "t_idx = 60\n",
    "traj_idx = 0\n",
    "\n",
    "flowfield = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(x_traj_data[traj_idx,:,t_idx]))) + q_sbf\n",
    "\n",
    "# flowfield = q_sbf\n",
    "\n",
    "#flowfield = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(Phi_cbal[:,-1])))\n",
    "\n",
    "\n",
    "# u, v, w, Z, R = output_fields(jet,jet.q_sbf)\n",
    "\n",
    "u, v, w, Z, R = output_fields(jet,flowfield)\n",
    "\n",
    "field = w\n",
    "color_map = 'hot_r'\n",
    "\n",
    "vminval = -np.max(field)*0\n",
    "vmaxval = np.max(field)\n",
    "\n",
    "plt.figure()\n",
    "plt.contourf(Z,R,w,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "ax.set_ylim([0,1.5])\n",
    "ax.set_xlabel('z',fontsize=14)\n",
    "ax.set_ylabel('r',fontsize=14)\n",
    "\n",
    "m = plt.cm.ScalarMappable(cmap=color_map)\n",
    "m.set_array(field)\n",
    "m.set_clim(vminval,vmaxval)\n",
    "\n",
    "cbar = plt.gcf().colorbar(m,orientation='horizontal',pad=0.2)\n",
    "cbar.ax.set_xlabel('Azimuthal vorticity',fontsize=14)\n",
    "cbar.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f522f",
   "metadata": {},
   "source": [
    "# Covariance Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13b885",
   "metadata": {},
   "source": [
    "## Gradient Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892af0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize large vectors (for efficiency)\n",
    "eta = np.zeros(lops.Mrem.shape[0])\n",
    "lam_fc = eta.copy()\n",
    "x0 = eta.copy()\n",
    "\n",
    "# horizon length\n",
    "L = 40\n",
    "delta_t_samples = t_data[1]-t_data[0]\n",
    "\n",
    "# number of samples per trajectories\n",
    "#n_samples = len(t_data)*(L+1) # 100\n",
    "n_samples = 10 # at random\n",
    "i0 = 0 # initial sample index (use for adding to an existing set of samples)\n",
    "n_traj = len(alphas)\n",
    "\n",
    "wclock0 = tlib.time()\n",
    "for k in range(n_traj):\n",
    "    \n",
    "    print(\"Current trajectory: %d\"%(k+1))\n",
    "    \n",
    "    ### construct gradient sample matrix\n",
    "    \n",
    "    # generate random final time samples\n",
    "    tf_idx_samples = np.zeros(n_samples, dtype=np.intp)\n",
    "    for i in range(n_samples):\n",
    "        t_idx = np.random.randint(0, len(t_data))\n",
    "        tau_idx = np.random.randint(0, L)\n",
    "        tf_idx_samples[i] = t_idx + tau_idx\n",
    "    \n",
    "#    # generate deterministic final time samples\n",
    "#    tf_idx_samples = np.zeros(n_samples, dtype=np.intp)\n",
    "#    for i in range(len(t_data)):\n",
    "#        for j in range(L+1):\n",
    "#            tf_idx_samples[i*(L+1)+j] = i + j\n",
    "    \n",
    "    # loop through samples\n",
    "    for i in range(n_samples):\n",
    "        \n",
    "        print(\"Current sample: %d\"%(i+1))\n",
    "        ## define the mini-trajectory\n",
    "        \n",
    "        # final time index\n",
    "        tf_idx = tf_idx_samples[i]\n",
    "        \n",
    "        # overlap with base trajectory (t = tf - tau)\n",
    "        tau_idx_min = max(0, tf_idx-len(t_data))\n",
    "        tau_idx_max = min(L, tf_idx)\n",
    "        nu = 1 + tau_idx_max - tau_idx_min\n",
    "        tau_idx_samples = np.arange(tau_idx_min, tau_idx_max+1)\n",
    "        tau_samples = tau_idx_samples * delta_t_samples\n",
    "        \n",
    "        # initial time index\n",
    "        t0_idx = tf_idx - tau_idx_max\n",
    "        \n",
    "        # initial and final times for mini-traj\n",
    "        t0 = t_data[t0_idx]\n",
    "        tf = t0 + delta_t_samples*(tf_idx - t0_idx)\n",
    "        \n",
    "        ## simulate forward along mini-trajectory\n",
    "        x0[:] = x_traj_data[k,:,t0_idx]\n",
    "        \n",
    "        if t0_idx < tf_idx:\n",
    "            \n",
    "            tspan = np.linspace(t0,tf,nsave*(tf_idx - t0_idx)+1)\n",
    "            sol_nonlin, _ = simulate_nonlinear_forward(jet,lops,x0,tspan,1)\n",
    "            \n",
    "            # random isotropic vector\n",
    "            eta[:] = np.sqrt(L+1)*np.random.randn(sol_nonlin.shape[0])\n",
    "            lam_fc[:] = eta\n",
    "            \n",
    "            \n",
    "            sol_adj, _ = simulate_linear_adjoint(jet,lops,lam_fc,tspan,nsave,sol_nonlin)\n",
    "            \n",
    "            # extract adjoint samples that overlap with data\n",
    "            sol_adj = sol_adj[:,:nu]\n",
    "            \n",
    "            Y_samples = sol_adj / np.sqrt(nu)\n",
    "            \n",
    "            x_samples = sol_nonlin[:,::nsave]\n",
    "            x_Y_samples = x_samples[:,:nu]\n",
    "            \n",
    "            del sol_nonlin\n",
    "            \n",
    "        else:\n",
    "            # random isotropic vector\n",
    "            eta[:] = np.sqrt(L+1)*np.random.randn(sol_nonlin.shape[0])\n",
    "            lam_fc[:] = eta\n",
    "            \n",
    "            Y_samples = np.reshape(lam_fc, (-1,1))\n",
    "            \n",
    "            x_Y_samples = np.reshape(x0, (-1,1))\n",
    "        \n",
    "        fname = 'data/cbal_L{:d}_traj{:d}_sample{:d}.mat'.format(L, k, i0+i)\n",
    "        data = {'Y_samples': Y_samples, \\\n",
    "                'x_Y_samples': x_Y_samples}\n",
    "        \n",
    "        with open(fname, 'wb') as fh:\n",
    "           pickle.dump(data, fh)\n",
    "        \n",
    "        del Y_samples, x_Y_samples, data\n",
    "\n",
    "wclock1 = tlib.time()\n",
    "print(\"Total runtime: %1.3e\"%((wclock1-wclock0)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2246273",
   "metadata": {},
   "source": [
    "## Load gradient samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizon length\n",
    "L = 40\n",
    "\n",
    "# number of samples per trajectories\n",
    "#n_samples = len(t_data)*(L+1) # 100\n",
    "n_samples = 10\n",
    "n_traj = len(alphas)\n",
    "\n",
    "# gradient sample matrix\n",
    "Y_samples = []\n",
    "# states at gradient samples\n",
    "x_Y_samples = []\n",
    "for k in range(n_traj):\n",
    "    print('loading samples from trajectory {:d} of {:d}\\n'.format(k+1, n_traj))\n",
    "    for i in range(n_samples):\n",
    "        fname = 'data/cbal_L{:d}_traj{:d}_sample{:d}.mat'.format(L, k, i)\n",
    "        with open(fname, 'rb') as fh:\n",
    "           data = pickle.load(fh)\n",
    "        \n",
    "        Y_samples = Y_samples + [data['Y_samples']]\n",
    "        x_Y_samples = x_Y_samples + [data['x_Y_samples']]\n",
    "\n",
    "# stack adjoint samples\n",
    "Y = np.hstack(Y_samples) / np.sqrt(n_traj*n_samples)\n",
    "del Y_samples\n",
    "\n",
    "x_Y = np.hstack(x_Y_samples)\n",
    "del x_Y_samples\n",
    "\n",
    "### state sample matrix\n",
    "X = np.hstack(x_traj_data)/np.sqrt(n_traj*len(t_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a281c0",
   "metadata": {},
   "source": [
    "## Save covariance balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65aa8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/cbal_L{:d}_{:d}trajs_by_{:d}samples.mat'.format(L, n_traj, n_samples)\n",
    "data = {'X': X, \\\n",
    "        'Y': Y, \\\n",
    "        'x_Y': x_Y}\n",
    "\n",
    "with open(fname, 'wb') as fh:\n",
    "   pickle.dump(data, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bf383",
   "metadata": {},
   "source": [
    "## Load covariance balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40826e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 40\n",
    "\n",
    "n_samples = 10\n",
    "n_traj = 12\n",
    "\n",
    "fname = 'data/cbal_L{:d}_{:d}trajs_by_{:d}samples.mat'.format(L, n_traj, n_samples)\n",
    "\n",
    "with open(fname, 'rb') as fh:\n",
    "   data = pickle.load(fh)\n",
    "\n",
    "X = data['X']\n",
    "Y = data['Y']\n",
    "x_Y = data['x_Y']\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753fb2a",
   "metadata": {},
   "source": [
    "## construct projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_cbal, s_cbal, VT = sp.linalg .svd(Y.T@X)\n",
    "V_cbal = VT.T\n",
    "\n",
    "var_frac_cbal = np.cumsum(np.square(s_cbal))/np.sum(np.square(s_cbal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2faec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(np.arange(len(s_cbal))+1, 1.0 - var_frac_cbal, 'ko')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d16d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 40\n",
    "Phi_cbal = X@V_cbal[:,:r]/np.sqrt(s_cbal[:r])\n",
    "Psi_cbal = Y@U_cbal[:,:r]/np.sqrt(s_cbal[:r])\n",
    "\n",
    "# construct reduced-order model\n",
    "f0_cbal, A_cbal, B_cbal, C_cbal, H_cbal, N_cbal = assemble_rom(jet,lops, Phi_cbal, Psi_cbal)\n",
    "\n",
    "def cbal_ROM(z, u):\n",
    "    # nonlinearity\n",
    "    fN = np.einsum('ijk,j,k', H_cbal, z, z)\n",
    "    return f0_cbal + np.dot(A_cbal, z) + fN + np.dot(B_cbal, u)\n",
    "\n",
    "def cbal_ROM_Jac(z, u):\n",
    "    J = A_cbal + \\\n",
    "        np.einsum('ijk, k', H_cbal, z) + \\\n",
    "        np.einsum('ijk, j', H_cbal, z)\n",
    "    \n",
    "    return J\n",
    "\n",
    "def cbal_ROM_obs(z):\n",
    "    return np.dot(C_cbal, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77234016",
   "metadata": {},
   "source": [
    "## Trajectory predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7635ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict trajectory\n",
    "\n",
    "n_traj = len(alphas)\n",
    "z_cbal_pred = np.inf*np.ones((n_traj, A_cbal.shape[0], len(t_data)))\n",
    "for k in range(n_traj):\n",
    "    # simulate the ROM trajectory\n",
    "    u = sp.interpolate.interp1d(time, u_traj[k,:,:], axis=1)\n",
    "    z0 = B_cbal[:,0]*alphas[k]\n",
    "    sol = sp.integrate.solve_ivp(lambda t,z: cbal_ROM(z, u(t)), \\\n",
    "                                 jac = lambda t,z: cbal_ROM_Jac(z, u(t)), \\\n",
    "                                 t_span = [t_data[0], t_data[-1]], \\\n",
    "                                 y0 = z0, \\\n",
    "                                 t_eval = t_data, \\\n",
    "                                 method = 'BDF')\n",
    "    \n",
    "    z_cbal_pred[k,:,:sol.y.shape[1]] = sol.y\n",
    "\n",
    "## compute error\n",
    "gt_energy = np.mean(np.square(np.linalg.norm(x_traj_data, axis=1)), axis=1)\n",
    "\n",
    "cbal_sq_errors = np.square(np.linalg.norm(np.einsum('ijl,kj', z_cbal_pred, Phi_cbal) - x_traj_data, axis=1)) / \\\n",
    "                    np.reshape(gt_energy, (-1,1))\n",
    "\n",
    "cbal_energy = np.square(np.linalg.norm(np.einsum('ijl,kj', z_cbal_pred, Phi_cbal), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0761770",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "k=0\n",
    "ax1.semilogy(t_data, cbal_sq_errors[k,:], color='#1f78b4', linestyle='-', label='cov. bal.')\n",
    "#ax1.semilogy(t_data, POD_sq_errors[k,:], color='#a6cee3', linestyle=':', label='POD')\n",
    "for k in range(1, n_traj):\n",
    "    ax1.semilogy(t_data, cbal_sq_errors[k,:], color='#1f78b4', linestyle='-')\n",
    "    #ax1.semilogy(t_data, POD_sq_errors[k,:], color='#a6cee3', linestyle=':')\n",
    "\n",
    "ax1.set_ylabel('normalized square error')\n",
    "\n",
    "ax1.set_xlabel('t')\n",
    "\n",
    "#axs[1].set_yticks([])\n",
    "\n",
    "# ax1.set_xticks(np.arange(6))\n",
    "\n",
    "ax1.set_ylim([1.0e-3, 1.0e2])\n",
    "\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# plt.savefig('figures/toy_model/test_data_normalized_sqaure_error.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('figures/toy_model/test_data_normalized_sqaure_error.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_idx = 40\n",
    "traj_idx = np.argmax(gt_energy)\n",
    "# traj_idx = np.argsort(gt_energy)[n_traj//2]\n",
    "# traj_idx = np.random.randint(n_traj)\n",
    "\n",
    "flowfield_gt = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(x_traj_data[traj_idx,:,t_idx]))) + q_sbf\n",
    "flowfield_cbal = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot( np.dot(Phi_cbal,z_cbal_pred[traj_idx,:,t_idx]) ))) + q_sbf\n",
    "\n",
    "_, _, w_gt, Z, R = output_fields(jet,flowfield_gt)\n",
    "_, _, w_cbal, _, _ = output_fields(jet,flowfield_cbal)\n",
    "\n",
    "\n",
    "vminval = 0.0\n",
    "vmaxval = 10.0\n",
    "color_map = 'hot_r'\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "axs[0].contourf(Z,R,w_gt,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "axs[1].contourf(Z,R,w_cbal,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "\n",
    "axs[0].set_aspect(1)\n",
    "axs[1].set_aspect(1)\n",
    "\n",
    "axs[0].set_ylim([0,1.5])\n",
    "axs[1].set_ylim([0,1.5])\n",
    "\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(c, cax=cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e488971",
   "metadata": {},
   "source": [
    "# POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.hstack(x_traj_data) / np.sqrt(n_traj * len(t_data))\n",
    "\n",
    "U_POD, s_POD, VT_POD = np.linalg.svd(X, full_matrices=False, compute_uv=True)\n",
    "var_frac_POD = np.cumsum(np.square(s_POD))/np.sum(np.square(s_POD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9df9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(np.arange(len(s_POD))+1, 1.0 - var_frac_POD, 'ko')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 40\n",
    "\n",
    "Phi_POD = U_POD[:,:r]\n",
    "Psi_POD = U_POD[:,:r]\n",
    "\n",
    "# construct reduced-order model\n",
    "f0_POD, A_POD, B_POD, C_POD, H_POD, N_POD = assemble_rom(jet,lops, Phi_POD, Psi_POD)\n",
    "\n",
    "def POD_ROM(z, u):\n",
    "    # nonlinearity\n",
    "    fN = np.einsum('ijk,j,k', H_POD, z, z)\n",
    "    return f0_POD + np.dot(A_POD, z) + fN + np.dot(B_POD, u)\n",
    "\n",
    "def POD_ROM_Jac(z, u):\n",
    "    J = A_POD + \\\n",
    "        np.einsum('ijk, k', H_POD, z) + \\\n",
    "        np.einsum('ijk, j', H_POD, z)\n",
    "    \n",
    "    return J\n",
    "\n",
    "def POD_ROM_obs(z):\n",
    "    return np.dot(C_POD, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b4629",
   "metadata": {},
   "source": [
    "## Trajectory predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict trajectory\n",
    "\n",
    "n_traj = len(alphas)\n",
    "z_POD_pred = np.inf*np.ones((n_traj, A_POD.shape[0], len(t_data)))\n",
    "for k in range(n_traj):\n",
    "    # simulate the ROM trajectory\n",
    "    u = sp.interpolate.interp1d(time, u_traj[k,:,:], axis=1)\n",
    "    z0 = B_POD[:,0]*alphas[k]\n",
    "    sol = sp.integrate.solve_ivp(lambda t,z: POD_ROM(z, u(t)), \\\n",
    "                                 jac = lambda t,z: POD_ROM_Jac(z, u(t)), \\\n",
    "                                 t_span = [t_data[0], t_data[-1]], \\\n",
    "                                 y0 = z0, \\\n",
    "                                 t_eval = t_data, \\\n",
    "                                 method = 'BDF')\n",
    "    \n",
    "    z_POD_pred[k,:,:sol.y.shape[1]] = sol.y\n",
    "\n",
    "## compute error\n",
    "gt_energy = np.mean(np.square(np.linalg.norm(x_traj_data, axis=1)), axis=1)\n",
    "\n",
    "POD_sq_errors = np.square(np.linalg.norm(np.einsum('ijl,kj', z_POD_pred, Phi_POD) - x_traj_data, axis=1)) / \\\n",
    "                    np.reshape(gt_energy, (-1,1))\n",
    "\n",
    "POD_energy = np.square(np.linalg.norm(np.einsum('ijl,kj', z_POD_pred, Phi_POD), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3712007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "k=0\n",
    "ax1.semilogy(t_data, POD_sq_errors[k,:], color='#a6cee3', linestyle=':', label='POD')\n",
    "for k in range(1, n_traj):\n",
    "    ax1.semilogy(t_data, POD_sq_errors[k,:], color='#a6cee3', linestyle=':')\n",
    "\n",
    "ax1.set_ylabel('normalized square error')\n",
    "\n",
    "ax1.set_xlabel('t')\n",
    "\n",
    "#axs[1].set_yticks([])\n",
    "\n",
    "# ax1.set_xticks(np.arange(6))\n",
    "\n",
    "ax1.set_ylim([1.0e-3, 1.0e2])\n",
    "\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# plt.savefig('figures/toy_model/test_data_normalized_sqaure_error.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('figures/toy_model/test_data_normalized_sqaure_error.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c009593",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_idx = 30\n",
    "traj_idx = np.argmax(gt_energy)\n",
    "# traj_idx = np.argsort(gt_energy)[n_traj//2]\n",
    "# traj_idx = np.random.randint(n_traj)\n",
    "\n",
    "flowfield_gt = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(x_traj_data[traj_idx,:,t_idx]))) + q_sbf\n",
    "flowfield_POD = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot( np.dot(Phi_POD,z_POD_pred[traj_idx,:,t_idx]) ))) + q_sbf\n",
    "\n",
    "_, _, w_gt, Z, R = output_fields(jet,flowfield_gt)\n",
    "_, _, w_POD, _, _ = output_fields(jet,flowfield_POD)\n",
    "\n",
    "\n",
    "vminval = 0.0\n",
    "vmaxval = 10.0\n",
    "color_map = 'hot_r'\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "axs[0].contourf(Z,R,w_gt,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "axs[1].contourf(Z,R,w_POD,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "\n",
    "axs[0].set_aspect(1)\n",
    "axs[1].set_aspect(1)\n",
    "\n",
    "axs[0].set_ylim([0,1.5])\n",
    "axs[1].set_ylim([0,1.5])\n",
    "\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(c, cax=cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0255973",
   "metadata": {},
   "source": [
    "# BPOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c01687",
   "metadata": {},
   "source": [
    "## Linear forward samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ce5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear impulse response about the steady base flow\n",
    "X_BPOD, _ = simulate_linear_forward(jet,lops,lops.Mrem.dot(lops.B),time,nsave)\n",
    "\n",
    "# output projection\n",
    "U_op, s_op, VT_op = np.linalg.svd(X_BPOD, full_matrices=False, compute_uv=True)\n",
    "var_frac_op = np.cumsum(np.square(s_op))/np.sum(np.square(s_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c13151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine output projection rank\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(len(s_op))+1, 1.0 - var_frac_op, 'ko')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3f89a",
   "metadata": {},
   "source": [
    "## Adjoint samples with output projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_op = 20\n",
    "\n",
    "Y_BPOD = [np.zeros(X_BPOD.shape) for _ in range(r_op)]\n",
    "for i in range(r_op):\n",
    "    print(\"adjoint sample {:d} of {:d} \\n\".format(i+1, r_op))\n",
    "    Y_BPOD[i][:,:], _ = simulate_linear_adjoint(jet,lops,U_op[:,i],time,nsave)\n",
    "\n",
    "Y_BPOD = np.hstack(Y_BPOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25ba4f",
   "metadata": {},
   "source": [
    "## Save BPOD sample matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51330abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/BPOD_{:d}op.mat'.format(r_op)\n",
    "data = {'X_BPOD': X_BPOD, \\\n",
    "        'Y_BPOD': Y_BPOD}\n",
    "\n",
    "with open(fname, 'wb') as fh:\n",
    "   pickle.dump(data, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb35ad",
   "metadata": {},
   "source": [
    "## Load BPOD sample matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6cfd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_op = 20\n",
    "\n",
    "fname = 'data/BPOD_{:d}op.mat'.format(r_op)\n",
    "\n",
    "with open(fname, 'rb') as fh:\n",
    "   data = pickle.load(fh)\n",
    "\n",
    "X_BPOD = data['X_BPOD']\n",
    "Y_BPOD = data['Y_BPOD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed98b01",
   "metadata": {},
   "source": [
    "## Construct projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_BPOD, s_BPOD, VT = sp.linalg .svd(Y_BPOD.T@X_BPOD)\n",
    "# U_BPOD, s_BPOD, VT = sp.linalg .svd(Y_BPOD.T@X)\n",
    "V_BPOD = VT.T\n",
    "\n",
    "var_frac_BPOD = np.cumsum(np.square(s_BPOD))/np.sum(np.square(s_BPOD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(np.arange(len(s_BPOD))+1, 1.0 - var_frac_BPOD, 'ko')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc8450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 40\n",
    "Phi_BPOD = X_BPOD@V_BPOD[:,:r]/np.sqrt(s_BPOD[:r])\n",
    "# Phi_BPOD = X@V_BPOD[:,:r]/np.sqrt(s_BPOD[:r])\n",
    "Psi_BPOD = Y_BPOD@U_BPOD[:,:r]/np.sqrt(s_BPOD[:r])\n",
    "\n",
    "# construct reduced-order model\n",
    "f0_BPOD, A_BPOD, B_BPOD, C_BPOD, H_BPOD, N_BPOD = assemble_rom(jet,lops, Phi_BPOD, Psi_BPOD)\n",
    "\n",
    "def BPOD_ROM(z, u):\n",
    "    # nonlinearity\n",
    "    fN = np.einsum('ijk,j,k', H_BPOD, z, z)\n",
    "    return f0_BPOD + np.dot(A_BPOD, z) + fN + np.dot(B_BPOD, u)\n",
    "\n",
    "def BPOD_ROM_Jac(z, u):\n",
    "    J = A_BPOD + \\\n",
    "        np.einsum('ijk, k', H_BPOD, z) + \\\n",
    "        np.einsum('ijk, j', H_BPOD, z)\n",
    "    \n",
    "    return J\n",
    "\n",
    "def BPOD_ROM_obs(z):\n",
    "    return np.dot(C_BPOD, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d379dad",
   "metadata": {},
   "source": [
    "## Trajectory predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eadc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict trajectory\n",
    "\n",
    "n_traj = len(alphas)\n",
    "z_BPOD_pred = np.inf*np.ones((n_traj, A_BPOD.shape[0], len(t_data)))\n",
    "for k in range(n_traj):\n",
    "    # simulate the ROM trajectory\n",
    "    u = sp.interpolate.interp1d(time, u_traj[k,:,:], axis=1)\n",
    "    z0 = B_BPOD[:,0]*alphas[k]\n",
    "    sol = sp.integrate.solve_ivp(lambda t,z: BPOD_ROM(z, u(t)), \\\n",
    "                                 jac = lambda t,z: BPOD_ROM_Jac(z, u(t)), \\\n",
    "                                 t_span = [t_data[0], t_data[-1]], \\\n",
    "                                 y0 = z0, \\\n",
    "                                 t_eval = t_data, \\\n",
    "                                 method = 'BDF')\n",
    "    \n",
    "    z_BPOD_pred[k,:,:sol.y.shape[1]] = sol.y\n",
    "\n",
    "## compute error\n",
    "gt_energy = np.mean(np.square(np.linalg.norm(x_traj_data, axis=1)), axis=1)\n",
    "\n",
    "BPOD_sq_errors = np.square(np.linalg.norm(np.einsum('ijl,kj', z_BPOD_pred, Phi_BPOD) - x_traj_data, axis=1)) / \\\n",
    "                    np.reshape(gt_energy, (-1,1))\n",
    "\n",
    "BPOD_energy = np.square(np.linalg.norm(np.einsum('ijl,kj', z_BPOD_pred, Phi_BPOD), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "k=0\n",
    "ax1.semilogy(t_data, BPOD_sq_errors[k,:], color='#b2df8a', linestyle='--', label='BPOD')\n",
    "for k in range(1, n_traj):\n",
    "    ax1.semilogy(t_data, BPOD_sq_errors[k,:], color='#b2df8a', linestyle='--')\n",
    "\n",
    "ax1.set_ylabel('normalized square error')\n",
    "\n",
    "ax1.set_xlabel('t')\n",
    "\n",
    "#axs[1].set_yticks([])\n",
    "\n",
    "# ax1.set_xticks(np.arange(6))\n",
    "\n",
    "ax1.set_ylim([1.0e-3, 1.0e2])\n",
    "\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# plt.savefig('figures/toy_model/test_data_normalized_sqaure_error.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('figures/toy_model/test_data_normalized_sqaure_error.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f66af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_idx = 10\n",
    "traj_idx = np.argmax(gt_energy)\n",
    "# traj_idx = np.argsort(gt_energy)[n_traj//2]\n",
    "# traj_idx = np.random.randint(n_traj)\n",
    "\n",
    "flowfield_gt = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(x_traj_data[traj_idx,:,t_idx]))) + q_sbf\n",
    "flowfield_BPOD = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot( np.dot(Phi_BPOD,z_BPOD_pred[traj_idx,:,t_idx]) ))) + q_sbf\n",
    "\n",
    "_, _, w_gt, Z, R = output_fields(jet,flowfield_gt)\n",
    "_, _, w_BPOD, _, _ = output_fields(jet,flowfield_BPOD)\n",
    "\n",
    "\n",
    "vminval = 0.0\n",
    "vmaxval = 10.0\n",
    "color_map = 'hot_r'\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "axs[0].contourf(Z,R,w_gt,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "axs[1].contourf(Z,R,w_BPOD,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "\n",
    "axs[0].set_aspect(1)\n",
    "axs[1].set_aspect(1)\n",
    "\n",
    "axs[0].set_ylim([0,1.5])\n",
    "axs[1].set_ylim([0,1.5])\n",
    "\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(c, cax=cbar_ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e706fd",
   "metadata": {},
   "source": [
    "# TrOOP\n",
    "Here, we work with orthonormal representatives $\\Phi, \\Psi\\in\\mathbb{R}_*^{n,r}$ of the subspaces $V,W \\in \\mathcal{G}_{n,r}$ used to define the projection $$P_{V,W} = \\Phi (\\Psi^T\\Phi)^{-1}\\Psi^T$$\n",
    "\n",
    "paper:\n",
    "\n",
    "S. E. Otto, A. Padovan, and C. W. Rowley, ``Optimizing Oblique Projections for Nonlinear Systems using Trajectories'', SIAM Journal on Scientific Computing, Vol. 44, No. 3, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b729c",
   "metadata": {},
   "source": [
    "## Validate basic FOM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a15fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = Phi_cbal\n",
    "Psi = Psi_cbal\n",
    "\n",
    "f0_ROM, A_ROM, B_ROM, C_ROM, H_ROM, N_ROM = assemble_rom(jet,lops, Phi, Psi)\n",
    "\n",
    "def ROM(z, u):\n",
    "    f = f0_ROM + np.einsum('ij,...j', A_ROM, z) + np.einsum('ij,...j', B_ROM, u) + \\\n",
    "    np.einsum('ijk,...j,...k', H_ROM, z, z) + np.einsum('ijk,...j,...k', N_ROM, u, z)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = np.dot(Psi.T, x_traj_data[0,:,0])\n",
    "z = np.random.randn(r)\n",
    "u = np.random.randn(1)\n",
    "\n",
    "x = np.dot(Phi, z)\n",
    "xdot = rom.evaluate_f(jet,lops,x,u)\n",
    "zdot = np.dot(Psi.T, xdot)\n",
    "\n",
    "zdot_ROM = ROM(z, u)\n",
    "\n",
    "print(np.linalg.norm(zdot_ROM - zdot) / np.linalg.norm(zdot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3313304",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_traj_data[0,:,0]\n",
    "u = np.random.randn(1)\n",
    "v = np.random.randn(x.shape[0])\n",
    "\n",
    "df_v = rom.evaluate_df(jet,lops,x,u,v)\n",
    "\n",
    "eps = 1.0e-8\n",
    "\n",
    "df_v_fd = (rom.evaluate_f(jet,lops,x + eps*v,u) - rom.evaluate_f(jet,lops,x,u)) / eps\n",
    "\n",
    "print(np.linalg.norm(df_v_fd - df_v) / np.linalg.norm(df_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(X.shape[0])\n",
    "u = np.random.randn(1)\n",
    "v = np.random.randn(x.shape[0])\n",
    "w = np.random.randn(x.shape[0])\n",
    "\n",
    "df_v = rom.evaluate_df(jet,lops,x,u,v)\n",
    "dfT_w = rom.evaluate_df_adj(jet,lops,x,u,w)\n",
    "\n",
    "IP1 = np.dot(df_v, w)\n",
    "IP2 = np.dot(v, dfT_w)\n",
    "\n",
    "print(np.absolute(IP2 - IP1) / np.absolute(IP1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de0eb62",
   "metadata": {},
   "source": [
    "## Split up trajectories\n",
    "\n",
    "This was not actually necessary, but here is the code to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_TrOOP = 100\n",
    "n_split = len(t_data)//L_TrOOP\n",
    "n_traj_TrOOP = n_traj*n_split\n",
    "x_train_TrOOP = np.zeros((n_traj*n_split, x_traj_data.shape[1], L_TrOOP))\n",
    "for k in range(n_traj):\n",
    "    for l in range(n_split):\n",
    "        x_train_TrOOP[n_split*k+l,:,:] = x_traj_data[k,:,l*L_TrOOP:(l+1)*L_TrOOP]\n",
    "\n",
    "t_TrOOP = t_data[:L_TrOOP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35de8ea",
   "metadata": {},
   "source": [
    "## Grassmann functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269eb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grassmann_metric(X0, X1, Phi):\n",
    "    # assemble and factor Gram matrix\n",
    "    c, low = sp.linalg.cho_factor(np.dot(Phi.T, Phi))\n",
    "    \n",
    "    # evaluate metric by solving linear system\n",
    "    g = np.trace(sp.linalg.cho_solve((c, low), np.dot(X0.T, X1)))\n",
    "    \n",
    "    return g\n",
    "\n",
    "def project_onto_horizontal_subspace(X, Phi):\n",
    "    # assemble and factor Gram matrices\n",
    "    c, low = sp.linalg.cho_factor(np.dot(Phi.T, Phi))\n",
    "    \n",
    "    # orthogonal projection onto horizontal space\n",
    "    X_proj = X - np.dot(Phi, sp.linalg.cho_solve((c, low), np.dot(Phi.T, X)))\n",
    "    \n",
    "    return X_proj\n",
    "\n",
    "def Grassmann_exp(Phi, X):\n",
    "    # exponential map using an orthogonal representative Phi\n",
    "    # and returning an orthogonal representative.\n",
    "    # We use Theorem 2.3 in \n",
    "    # A. Edelman, T. A. Arias, S. T. Smith, ``The geometry of algorithms with \n",
    "    # orthogonality constraints'', SIAM J. Matrix Anal. Appl., 1998.\n",
    "    U, s, VT = sp.linalg.svd(X, full_matrices=False)\n",
    "    cos_s = np.reshape(np.cos(s), (1,-1))\n",
    "    sin_s = np.reshape(np.sin(s), (1,-1))\n",
    "    \n",
    "    exp_Phi_X = np.dot(Phi, np.dot(VT.T * cos_s, VT )) + np.dot(U * sin_s, VT)\n",
    "    return exp_Phi_X\n",
    "\n",
    "def Grassmann_exp_transport(Phi, X, Y):\n",
    "    # Transport tangent vector Y along the geodesic starting at Phi\n",
    "    # in the direction X\n",
    "    # We use Theorem 2.4 in \n",
    "    # A. Edelman, T. A. Arias, S. T. Smith, ``The geometry of algorithms with \n",
    "    # orthogonality constraints'', SIAM J. Matrix Anal. Appl., 1998.\n",
    "    U, s, VT = sp.linalg.svd(X, full_matrices=False)\n",
    "    cos_s = np.reshape(np.cos(s), (1,-1))\n",
    "    sin_s = np.reshape(np.sin(s), (1,-1))\n",
    "    \n",
    "    # exponential map\n",
    "    exp_Phi_X = np.dot(Phi, np.dot(VT.T * cos_s, VT )) + np.dot(U * sin_s, VT)\n",
    "    \n",
    "    # parallel translation\n",
    "    T = - np.dot(Phi, VT.T * sin_s) + U * cos_s\n",
    "    U_Y = np.dot(U.T, Y)\n",
    "    P_Phi_X_Y = np.dot(T, U_Y) + Y - np.dot(U, U_Y)\n",
    "    return exp_Phi_X, P_Phi_X_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21af14b",
   "metadata": {},
   "source": [
    "## Optimization objective and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42367e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1.0e-3\n",
    "\n",
    "## parameters for quadrature used to compute gradient\n",
    "n_quad = 3\n",
    "\n",
    "# Gauss-Legendre quadrature\n",
    "s_quad, w_quad = np.polynomial.legendre.leggauss(n_quad)\n",
    "\n",
    "# set tolerance for solvers\n",
    "atol = 1.0e-6\n",
    "rtol = 1.0e-9\n",
    "solver_method = 'RK45'\n",
    "\n",
    "# # Trapezoidal quadrature\n",
    "# s_quad = np.linspace(-1,1,n_quad)\n",
    "# w_quad = np.zeros(n_quad)\n",
    "# w_quad[0] = (s_quad[1] - s_quad[0])/2.0\n",
    "# w_quad[1:-1] = (s_quad[2:] - s_quad[0:-2])/2.0\n",
    "# w_quad[-1] = (s_quad[-1] - s_quad[-2])/2.0\n",
    "\n",
    "def regularization(Phi, Psi):\n",
    "    # regularization and gradient at orthonormal representatives Phi, Psi\n",
    "    G_Phi = np.dot(Phi.T, Phi)\n",
    "    G_Psi = np.dot(Psi.T, Psi)\n",
    "    A_lu, A_piv = sp.linalg.lu_factor(np.dot(Psi.T, Phi))\n",
    "    \n",
    "    _, c1 = np.linalg.slogdet(G_Phi)\n",
    "    _, c2 = np.linalg.slogdet(G_Psi)\n",
    "    _, c3 = np.linalg.slogdet(np.dot(Psi.T, Phi))\n",
    "    \n",
    "    rho = c1 + c2 - 2*c3\n",
    "    \n",
    "    Psi_AT = sp.linalg.lu_solve((A_lu, A_piv), Psi.T, trans=0).T\n",
    "    Phi_A = sp.linalg.lu_solve((A_lu, A_piv), Phi.T, trans=1).T\n",
    "    \n",
    "    grad_Phi = 2.0*(Phi - Psi_AT)\n",
    "    grad_Psi = 2.0*(Psi - Phi_A)\n",
    "    \n",
    "    return rho, grad_Phi, grad_Psi\n",
    "\n",
    "def objective(Phi, Psi):\n",
    "    r = Phi.shape[1]\n",
    "    # construct a bi-orthogonalized representative Psi_AT so that\n",
    "    # P_{V,W} = Phi * Psi_AT^T\n",
    "    A_lu, A_piv = sp.linalg.lu_factor(np.dot(Psi.T, Phi))\n",
    "    Psi_AT = sp.linalg.lu_solve((A_lu, A_piv), Psi.T, trans=0).T\n",
    "    \n",
    "    # construct a representative of the reduced-order model\n",
    "    f0_ROM, A_ROM, B_ROM, C_ROM, H_ROM, N_ROM = assemble_rom(jet,lops, Phi, Psi_AT)\n",
    "    \n",
    "    def ROM(z, u):\n",
    "        f = f0_ROM + np.einsum('ij,...j', A_ROM, z) + np.einsum('ij,...j', B_ROM, u) + \\\n",
    "        np.einsum('ijk,...j,...k', H_ROM, z, z) + np.einsum('ijk,...j,...k', N_ROM, u, z)\n",
    "        return f\n",
    "    \n",
    "#     def d_ROM(x, u, v):\n",
    "#         df_v = np.einsum('ij,...j', A_ROM, v) + \\\n",
    "#             2.0*np.einsum('ijk,...j,...k', H_ROM, x, v) + np.einsum('ijk,...j,...k', N_ROM, u, v)\n",
    "#         return df_v\n",
    "\n",
    "    # observation function\n",
    "    def ROM_obs(z):\n",
    "        g = np.einsum('ij,...j', C_ROM, z)\n",
    "        return g\n",
    "    \n",
    "    # compute the cost for each trajectory\n",
    "    try:\n",
    "        cost = 0.0\n",
    "        for k in range(n_traj_TrOOP):\n",
    "            # interpolate the input\n",
    "            u_fun = lambda t: np.zeros(1)# sp.interpolate.interp1d(time, u_traj[k,:,:], axis=1)\n",
    "            \n",
    "            # initial condition\n",
    "#             z_0 = B_ROM[:,0]*alphas[k]\n",
    "            z_0 = np.dot(Psi_AT.T, x_train_TrOOP[k,:,0])\n",
    "            \n",
    "            # simulate the ROM trajectory\n",
    "            sol = sp.integrate.solve_ivp(lambda t,z: ROM(z, u_fun(t)), \\\n",
    "#                                          jac = lambda t,z: d_ROM(z, u_fun(t), np.eye(r)), \\\n",
    "                                         t_span = [t_TrOOP[0], t_TrOOP[-1]], \\\n",
    "                                         y0 = z_0, \\\n",
    "                                         t_eval = t_TrOOP, \\\n",
    "                                         method = solver_method, \\\n",
    "                                         atol=atol, rtol=rtol)\n",
    "            \n",
    "            # construct ROM output\n",
    "            y_ROM = ROM_obs(sol.y.T)\n",
    "            \n",
    "            # compute cost along trajectory\n",
    "            tot_err_k = np.sum(np.square(np.linalg.norm( x_train_TrOOP[k,:,:].T - y_ROM, axis=1)))\n",
    "            tot_nrgy_k = np.sum(np.square(np.linalg.norm( x_train_TrOOP[k,:,:].T, axis=1)))\n",
    "            cost = cost + tot_err_k / tot_nrgy_k\n",
    "        \n",
    "        if np.isnan(cost):\n",
    "            cost = np.inf\n",
    "        \n",
    "    except:\n",
    "        cost = np.inf\n",
    "    \n",
    "    rho, _, _ = regularization(Phi, Psi)\n",
    "    \n",
    "    return cost/n_traj_TrOOP + gamma*rho\n",
    "\n",
    "def objective_grad(Phi, Psi):\n",
    "    r = Phi.shape[1]\n",
    "    # construct a bi-orthogonalized representative Psi_AT so that\n",
    "    # P_{V,W} = Phi * Psi_AT^T\n",
    "    A_lu, A_piv = sp.linalg.lu_factor(np.dot(Psi.T, Phi))\n",
    "    Psi_AT = sp.linalg.lu_solve((A_lu, A_piv), Psi.T, trans=0).T\n",
    "    \n",
    "    # construct a representative of the reduced-order model\n",
    "    f0_ROM, A_ROM, B_ROM, C_ROM, H_ROM, N_ROM = assemble_rom(jet,lops, Phi, Psi_AT)\n",
    "    \n",
    "    def ROM(z, u):\n",
    "        f = f0_ROM + np.einsum('ij,...j', A_ROM, z) + np.einsum('ij,...j', B_ROM, u) + \\\n",
    "        np.einsum('ijk,...j,...k', H_ROM, z, z) + np.einsum('ijk,...j,...k', N_ROM, u, z)\n",
    "        return f\n",
    "    \n",
    "#     def d_ROM(x, u, v):\n",
    "#         df_v = np.einsum('ij,...j', A_ROM, v) + \\\n",
    "#             2.0*np.einsum('ijk,...j,...k', H_ROM, x, v) + np.einsum('ijk,...j,...k', N_ROM, u, v)\n",
    "#         return df_v\n",
    "\n",
    "    # observation function\n",
    "    def ROM_obs(z):\n",
    "        g = np.einsum('ij,...j', C_ROM, z)\n",
    "        return g\n",
    "    \n",
    "    # adjoint of ROM acting on w\n",
    "    def d_ROM_adj(z, u, w):\n",
    "        df_T_w = np.einsum('ji,...j', A_ROM, w) + \\\n",
    "            2.0*np.einsum('kji,...j,...k', H_ROM, z, w) + np.einsum('kji,...j,...k', N_ROM, u, w)\n",
    "        return df_T_w\n",
    "    \n",
    "    # adjoint of ROM observations acting on w\n",
    "    def d_ROM_obs_adj(z, w):\n",
    "        dg_T_w = np.einsum('ji,...j', C_ROM, w)\n",
    "        return dg_T_w\n",
    "    \n",
    "    ## compute cost and gradient\n",
    "    cost = 0.0\n",
    "    grad_Phi = 0.0 * Phi\n",
    "    grad_Psi = 0.0 * Psi\n",
    "    \n",
    "#     for k in range(n_traj):\n",
    "    for k in tqdm(range(n_traj_TrOOP), position=0, leave=True, desc=\"computing gradient\"):\n",
    "        # interpolate the input\n",
    "        u_fun = lambda t: np.zeros(1)# sp.interpolate.interp1d(time, u_traj[k,:,:], axis=1)\n",
    "        \n",
    "        # initial condition\n",
    "        x_0 = x_train_TrOOP[k,:,0]\n",
    "        z_0 = np.dot(Psi_AT.T, x_0) # B_ROM[:,0]*alphas[k]\n",
    "        \n",
    "        # simulate the ROM trajectory\n",
    "        sol = sp.integrate.solve_ivp(lambda t,z: ROM(z, u_fun(t)), \\\n",
    "#                                      jac = lambda t,z: d_ROM(z, u_fun(t), np.eye(r)), \\\n",
    "                                     t_span = [t_TrOOP[0], t_TrOOP[-1]], \\\n",
    "                                     y0 = z_0, \\\n",
    "                                     dense_output=True, \\\n",
    "                                     method = solver_method, \\\n",
    "                                     atol=atol, rtol=rtol)\n",
    "        \n",
    "        # interpolants of the ROM solution\n",
    "        z_fun = lambda t: sol.sol(t).T\n",
    "        y_fun = lambda t: ROM_obs(sol.sol(t).T)\n",
    "        \n",
    "        # outputs at sample times\n",
    "        y_ROM = y_fun(t_TrOOP)\n",
    "        \n",
    "        # compute cost\n",
    "        tot_err_k = np.sum(np.square(np.linalg.norm( x_train_TrOOP[k,:,:].T - y_ROM, axis=1)))\n",
    "        tot_nrgy_k = np.sum(np.square(np.linalg.norm( x_train_TrOOP[k,:,:].T, axis=1)))\n",
    "        cost = cost + tot_err_k / tot_nrgy_k\n",
    "        \n",
    "        # cost gradient at each sample time\n",
    "        g_samples = -2.0 * (x_train_TrOOP[k,:,:].T - y_ROM) / tot_nrgy_k\n",
    "        \n",
    "        # construct F, S, H, T operators using prop. 4.3\n",
    "        F_adj = lambda t, v: rom. d_ROM_adj(z_fun(t), u_fun(t), v)\n",
    "        S_adj_Phi = lambda t, v: np.outer(rom.evaluate_df_adj(jet,lops,np.dot(Phi, z_fun(t)), \\\n",
    "                                                     u_fun(t), \\\n",
    "                                                     np.dot(Psi_AT, v)), \\\n",
    "                                          z_fun(t)) - \\\n",
    "                                np.outer(np.dot(Psi_AT, v), \\\n",
    "                                         ROM(z_fun(t), u_fun(t)))\n",
    "        S_adj_Psi = lambda t, v: np.outer(rom.evaluate_f(jet,lops,np.dot(Phi, z_fun(t)), u_fun(t)) - \\\n",
    "                                          np.dot(Phi, ROM(z_fun(t), u_fun(t))), \\\n",
    "                                          sp.linalg.lu_solve((A_lu, A_piv), v, trans=1).T)\n",
    "        H_adj = lambda t, v: d_ROM_obs_adj(z_fun(t), v)\n",
    "        T_adj_Phi = lambda t, v: np.outer(v, z_fun(t))\n",
    "        T_adj_Psi = lambda t, v: 0.0*Psi\n",
    "        IC_adj_Phi = lambda v: -np.outer(np.dot(Psi_AT,v), z_0)\n",
    "        IC_adj_Psi = lambda v: np.outer(x_0 - np.dot(Phi, z_0), \\\n",
    "                                        sp.linalg.lu_solve((A_lu, A_piv), v, trans=1).T)\n",
    "        \n",
    "        # add last element of sum component of gradient\n",
    "        tf = t_TrOOP[-1]\n",
    "        grad_Phi = grad_Phi + T_adj_Phi(tf, g_samples[-1,:])\n",
    "        grad_Psi = grad_Psi + T_adj_Psi(tf, g_samples[-1,:])\n",
    "        \n",
    "        # solve adjoint equation with jumps backwards in time\n",
    "        lam_f = H_adj(t_TrOOP[-1], g_samples[-1,:])\n",
    "        for l in range(len(t_TrOOP)-1):\n",
    "            # simulate adjoint dynamics (thm. 4.2)\n",
    "            # over the interval t_data[-2-l] to t_data[-1-l] with\n",
    "            # tau = t_data[-1] - t\n",
    "            \n",
    "            # sample points for quadrature\n",
    "            s_pts =  t_TrOOP[-2-l] + (t_TrOOP[-1-l] - t_TrOOP[-2-l])*(s_quad + 1.0)/2.0\n",
    "            tau_pts = tf - s_pts\n",
    "            \n",
    "            # scaled quadrature weights\n",
    "            w_scaled = w_quad * (t_TrOOP[-1-l] - t_TrOOP[-2-l])/2.0\n",
    "            \n",
    "            # integrate adjoint dynamics\n",
    "            adj_sol = sp.integrate.solve_ivp(lambda tau,lam: d_ROM_adj(z_fun(tf-tau), u_fun(tf-tau),lam), \\\n",
    "#                                     jac = lambda tau,lam: d_ROM_adj(z_fun(tf-tau), u_fun(tf-tau),np.eye(r)), \\\n",
    "                                    t_span = [tf-t_TrOOP[-1-l], tf-t_TrOOP[-2-l]], \\\n",
    "                                    y0 = lam_f, \\\n",
    "                                    dense_output=True, \\\n",
    "                                    method = solver_method, \\\n",
    "                                    atol=atol, rtol=rtol)\n",
    "            \n",
    "            # compute adjoint variable at quadrature points s_pts\n",
    "            lam = adj_sol.y[:,::-1].T\n",
    "            \n",
    "            # add integral component to gradient\n",
    "            for q in range(n_quad):\n",
    "                grad_Phi = grad_Phi + w_scaled[q]*S_adj_Phi(s_pts[q], adj_sol.sol(tau_pts[q]).T)\n",
    "                grad_Psi = grad_Psi + w_scaled[q]*S_adj_Psi(s_pts[q], adj_sol.sol(tau_pts[q]).T)\n",
    "            \n",
    "            # add element to sum component of gradient\n",
    "            grad_Phi = grad_Phi + T_adj_Phi(t_TrOOP[-2-l], g_samples[-2-l,:])\n",
    "            grad_Psi = grad_Psi + T_adj_Psi(t_TrOOP[-2-l], g_samples[-2-l,:])\n",
    "            \n",
    "            # add jump to adjoint variable\n",
    "            lam_f = adj_sol.sol(tf-t_TrOOP[-2-l]).T + H_adj(t_TrOOP[-2-l], g_samples[-2-l,:])\n",
    "        \n",
    "        # add gradient due to initial condition\n",
    "        grad_Phi = grad_Phi + IC_adj_Phi(lam_f)\n",
    "        grad_Psi = grad_Psi + IC_adj_Psi(lam_f)\n",
    "        \n",
    "    # compute regularization\n",
    "    rho, grad_rho_Phi, grad_rho_Psi = regularization(Phi, Psi)\n",
    "    \n",
    "    # compute normalized and regularized cost and gradient\n",
    "    cost = cost/n_traj_TrOOP + gamma*rho\n",
    "    grad_Phi = grad_Phi/n_traj_TrOOP + gamma*grad_rho_Phi\n",
    "    grad_Psi = grad_Psi/n_traj_TrOOP + gamma*grad_rho_Psi\n",
    "        \n",
    "    return cost, grad_Phi, grad_Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose subspaces\n",
    "Phi, _, _ = sp.linalg.qr(Phi_cbal, pivoting=True, mode='economic')\n",
    "Psi, _, _ = sp.linalg.qr(Psi_cbal, pivoting=True, mode='economic')\n",
    "\n",
    "# make sure orientation is correct\n",
    "s, _ = np.linalg.slogdet(np.dot(Psi.T, Phi))\n",
    "Phi[:,0] = s*Phi[:,0]\n",
    "\n",
    "# initial objective value and gradient\n",
    "f_val, grad_Phi, grad_Psi = objective_grad(Phi, Psi)\n",
    "print(f_val)\n",
    "\n",
    "# magnitude of the gradient\n",
    "grad_mag = np.sqrt(Grassmann_metric(grad_Phi, grad_Phi, Phi) + Grassmann_metric(grad_Psi, grad_Psi, Psi))\n",
    "print(grad_mag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0945ab99",
   "metadata": {},
   "source": [
    "### Validate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random perturbation in tangent space\n",
    "# X = project_onto_horizontal_subspace(np.random.randn(Phi.shape[0], Phi.shape[1])/np.sqrt(Phi.shape[0]), Phi)\n",
    "# Y = project_onto_horizontal_subspace(np.random.randn(Psi.shape[0], Psi.shape[1])/np.sqrt(Psi.shape[0]), Psi)\n",
    "\n",
    "X = project_onto_horizontal_subspace(grad_Phi/grad_mag, Phi)\n",
    "Y = project_onto_horizontal_subspace(grad_Psi/grad_mag, Psi)\n",
    "\n",
    "# derivative along (X,Y) as computed using gradient\n",
    "dfdt_grad = Grassmann_metric(grad_Phi, X, Phi) + Grassmann_metric(grad_Psi, Y, Psi)\n",
    "print(dfdt_grad)\n",
    "\n",
    "# apply exponential map to construct nearby point\n",
    "eps = 1.0e-10\n",
    "Phi_eps = Grassmann_exp(Phi, eps*X)\n",
    "Psi_eps = Grassmann_exp(Psi, eps*Y)\n",
    "f_eps = objective(Phi_eps, Psi_eps)\n",
    "\n",
    "# derivative using finite differences\n",
    "dfdt_fd = (f_eps - f_val)/eps\n",
    "print(dfdt_fd)\n",
    "\n",
    "print(np.absolute((dfdt_grad - dfdt_fd))/np.absolute(dfdt_fd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff3414",
   "metadata": {},
   "source": [
    "## Conjugate gradient functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search_objective(step, Phi, Psi, dir_X, dir_Y):\n",
    "    Phi_next = Grassmann_exp(Phi, step*dir_X)\n",
    "    Psi_next = Grassmann_exp(Psi, step*dir_Y)\n",
    "    f = objective(Phi_next, Psi_next)\n",
    "    return f\n",
    "\n",
    "def weak_Wolfe_bisection(slope, init_step_size, c1, c2, f0, f, fd_step, \\\n",
    "    max_iter=np.inf):\n",
    "    \"\"\" Bisection line search method to meet weak Wolfe conditions descibed in\n",
    "    https://sites.math.washington.edu/~burke/crs/408/notes/nlp/line.pdf.\n",
    "    The derivative along the search direction is computed using finite\n",
    "    differences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    slope: float\n",
    "        The slope along the search direction, i.e., the directional derivative \n",
    "        of the objective along the search direction.\n",
    "    init_step_size: float\n",
    "        A positive number giving the initial step size to consider along the\n",
    "        search direction.\n",
    "    c1: float\n",
    "        A number satisfying 0 < c1 < c2 < 1 giving the desired fraction of the \n",
    "        initial slope to be achieved by the average decrease of the objective \n",
    "        along the step.\n",
    "    c2: float\n",
    "        A number satisfying 0 < c1 < c2 < 1 giving the desired fraction by \n",
    "        which the slope along the search direction should increase.\n",
    "    f0: float\n",
    "        The value of the objective at the current step of the outer algorithm.\n",
    "    f: function\n",
    "        A function of the step size that retuns the value of the objective when\n",
    "        a step of a given size is taken. This function satisfies f0 = f(0) and \n",
    "        f'(0) = slope.\n",
    "    fd_step: float\n",
    "        A small positive number to be used as the step size for estimating the\n",
    "        derivative along the search direction by finite differences. If the\n",
    "        step_size is smaller that 10*fd_step, we use 0.1*fd_step for the finite\n",
    "        difference.\n",
    "    max_iter: integer\n",
    "        The maximum number of bisection iterations to perform. The default is\n",
    "        infinity since the algorithm is guaranteed to eventually converge.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    step_size: float\n",
    "        A step size meeting the weak Wolfe conditions (assuming the max_iter\n",
    "        is not reached).\n",
    "    f_next: float\n",
    "        The value of the objective after a step of the chosen size along the\n",
    "        search direction.\n",
    "    iter: integer\n",
    "        The number of iterations use to compute the step size.\n",
    "    \"\"\"\n",
    "    # desired fraction of slope along descent direction to be achieved by step\n",
    "    # this is the first weak Wolfe condition.\n",
    "    decrease_cond = -c1*slope\n",
    "\n",
    "    # maximum rate of decrease to meet the second weak Wolfe condition\n",
    "    curvature_cond = -c2*slope\n",
    "\n",
    "    # Initialization\n",
    "    alpha = 0\n",
    "    beta = np.inf\n",
    "    step_size = init_step_size\n",
    "\n",
    "    iter = 0\n",
    "    weak_Wolfe_cond = False\n",
    "    while iter < max_iter and not weak_Wolfe_cond:\n",
    "        # compute the objective value using the proposed step size\n",
    "        f_next = f(step_size)\n",
    "\n",
    "        if f0 - f_next < step_size * decrease_cond:\n",
    "            # sufficient decrease condition not met, decrease the step size.\n",
    "            beta = step_size\n",
    "            step_size = (alpha + beta)/2.0\n",
    "        else:\n",
    "            # sufficient decrease condition is met. Check curvature condition by\n",
    "            # computing the slope at the proposed step.\n",
    "            h = -np.min((fd_step, step_size/10.0))\n",
    "            df_next = (f(step_size + h) - f_next) / h\n",
    "\n",
    "            if -df_next > curvature_cond:\n",
    "                # rate of objective decrease is too high for second weak Wolfe\n",
    "                # condition. Adjust the step size.\n",
    "                alpha = step_size\n",
    "\n",
    "                if beta == np.inf:\n",
    "                    step_size = 2.0 * alpha\n",
    "                else:\n",
    "                    step_size = (alpha + beta)/2.0\n",
    "            \n",
    "            else:\n",
    "                # the weak Wolfe conditions are met, so iteration stops\n",
    "                weak_Wolfe_cond = True\n",
    "        \n",
    "        iter = iter + 1\n",
    "    \n",
    "    return step_size, f_next, iter\n",
    "\n",
    "def cg_step(Phi, Psi, f_val, dir_X, dir_Y, grad_X, grad_Y, init_step_size, \\\n",
    "    ls_params={'max_iter':np.inf, 'c1':0.1, 'c2':0.2, 'fd_step':1.0e-6}):\n",
    "    \"\"\"One step of the geometric conjugate gradient algorithm using bisection\n",
    "    line search to meet the weak Wolfe conditions. Next search direction is\n",
    "    computed using the Riemannian Dai-Yuan method of\n",
    "    \n",
    "    H. Sato, \"A Dai-Yuan-type Riemannian conjugate gradient method with the\n",
    "    weak Wolfe conditions\", 2016, Comput. Optim. and Appl.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Phi: array of shape (n_dim, r_basis)\n",
    "        Representative of the subspace V, i.e., the columns of Phi are an \n",
    "        orthonormal basis for V.\n",
    "    Psi: array of shape (n_dim, r_basis)\n",
    "        Representative of the subspace W, i.e., the columns of Psi are an \n",
    "        orthonormal basis for W.\n",
    "    f_val: float\n",
    "        Current value of the objective function\n",
    "    dir_X: array of shape (n_dim, r_basis)\n",
    "        Horizontal lift of the search direction for V in the tangent space\n",
    "        at Phi. In particular Phi^*dir_X = 0.\n",
    "    dir_Y: array of shape (n_dim, r_basis)\n",
    "        Horizontal lift of the search direction for W in the tangent space\n",
    "        at Psi. In particular Phi^*dir_X = 0.\n",
    "    grad_X: array of shape (n_dim, r_basis)\n",
    "        Horizontal lift of gradient wrt V at Phi.\n",
    "    grad_Y: array of shape (n_dim, r_basis)\n",
    "        Horizontal lift of gradient wrt W at Psi\n",
    "    init_step_size: float\n",
    "        A positive number giving the initial step size along the search \n",
    "        direction.\n",
    "    ls_params: dictionary\n",
    "        Parameters for the line search method. Includes:\n",
    "            max_iter: integer\n",
    "                The maximum number of bisection iterations to perform.\n",
    "            c1: float\n",
    "                A number satisfying 0 < c1 < c2 < 1 giving the desired fraction \n",
    "                of the initial slope to be achieved by the average decrease of \n",
    "                the objective along the step.\n",
    "            c2: float\n",
    "                A number satisfying 0 < c1 < c2 < 1 giving the desired fraction \n",
    "                by which the slope along the search direction should increase.\n",
    "            fd_step: float\n",
    "                Step size used to compute the derivative along the line search\n",
    "                direction. When step_size < 10*fd_step, we reduce this value to \n",
    "                0.1*step_size.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Phi_next: array of shape (n_dim, r_basis)\n",
    "        Orthonormal representative of V at the next step\n",
    "    Psi_next: array of shape (n_dim, r_basis)\n",
    "        Orthonormal representative of W at the next step  \n",
    "    dir_X_next: array of shape (n_dim, r_basis)\n",
    "        Horizontal lift of the next search direction for V at Phi_next\n",
    "    dir_Y_next: array of shape (n_dim, r_basis)\n",
    "        Horizontal lift of the next search direction for W at Psi_next\n",
    "    grad_X_next: array of shape (n_dim, r_basis)\n",
    "        Horizontal lift of gradient wrt V at Phi_next\n",
    "    grad_Y_next: array of shape (n_dim, r_basis)\n",
    "        Horizontal lift of gradient wrt W at Psi_next\n",
    "    step_size: float\n",
    "        The step size computed using the bisection method to meet the weak \n",
    "        Wolfe conditions.\n",
    "    f_val_next: float\n",
    "        The value of the objective at (Phi_next, Phi_next).\n",
    "    iter: integer\n",
    "        The number of iterations used to find the step size.\n",
    "    \"\"\"\n",
    "    # normalize the step size\n",
    "    #   in particular, the user works with an absolute steps size, whereas this\n",
    "    #   algorith uses a relative step size that multiplies dir_X and dir_Y\n",
    "    dir_mag = np.sqrt(Grassmann_metric(dir_X, dir_X, Phi) + \\\n",
    "                      Grassmann_metric(dir_Y, dir_Y, Psi))\n",
    "    init_step_size = init_step_size/dir_mag\n",
    "\n",
    "    ## compute step size along search direction using bisection method to meet\n",
    "    # the weak Wolfe conditions\n",
    "\n",
    "    # compute derivative of objective along line search direction\n",
    "    slope = Grassmann_metric(grad_X, dir_X, Phi) + \\\n",
    "                Grassmann_metric(grad_Y, dir_Y, Psi)\n",
    "\n",
    "    # objective function along line search direction\n",
    "    f_line_search = lambda step : line_search_objective(step, Phi, Psi, \\\n",
    "                                                        dir_X, dir_Y)\n",
    "    \n",
    "    # compute the step size and next objective value\n",
    "    step_size, f_val_next, iter = weak_Wolfe_bisection(slope, \\\n",
    "            init_step_size, ls_params['c1'], ls_params['c2'], f_val, \\\n",
    "            f_line_search, ls_params['fd_step']/dir_mag, ls_params['max_iter'])\n",
    "    \n",
    "    ## compute next iterate and transport search direction to new point\n",
    "    Phi_next, T_dir_X = Grassmann_exp_transport(Phi, step_size*dir_X, dir_X)\n",
    "    Psi_next, T_dir_Y = Grassmann_exp_transport(Psi, step_size*dir_Y, dir_Y)\n",
    "\n",
    "    ## compute the gradient at the next step\n",
    "    \n",
    "    # make sure that orientation is correct\n",
    "    s, _ = np.linalg.slogdet(np.dot(Psi_next.T, Phi_next))\n",
    "    Phi_next[:,0] = s * Phi_next[:,0]\n",
    "    T_dir_X[:,0] = s * T_dir_X[:,0]\n",
    "    \n",
    "    # compute gradient\n",
    "    _, grad_X_next, grad_Y_next = objective_grad(Phi_next, Psi_next)\n",
    "\n",
    "    # Project the gradient onto the horizontal subspace at the next point.\n",
    "    # This should not do anything because the gradient should already lie in\n",
    "    # the horizontal space. But we keep to ensure this holds to high numerical\n",
    "    # precision.\n",
    "    grad_X_next = project_onto_horizontal_subspace(grad_X_next, Phi_next)\n",
    "    grad_Y_next = project_onto_horizontal_subspace(grad_Y_next, Psi_next)\n",
    "    \n",
    "    ## compute the next search direction\n",
    "    \n",
    "    # compute components of the combination coefficient\n",
    "    a = Grassmann_metric(grad_X_next, grad_X_next, Phi_next) + \\\n",
    "            Grassmann_metric(grad_Y_next, grad_Y_next, Psi_next)\n",
    "    b = Grassmann_metric(grad_X_next, T_dir_X, Phi_next) + \\\n",
    "            Grassmann_metric(grad_Y_next, T_dir_Y, Psi_next)\n",
    "    c = Grassmann_metric(grad_X, dir_X, Phi) + \\\n",
    "            Grassmann_metric(grad_Y, dir_Y, Psi)\n",
    "    \n",
    "    # combination coefficient\n",
    "    beta = a / (b - c)\n",
    "    \n",
    "    # horizontal lift of the next search direction\n",
    "    dir_X_next = -grad_X_next + beta*T_dir_X\n",
    "    dir_Y_next = -grad_Y_next + beta*T_dir_Y\n",
    "    \n",
    "    # convert back to absolute step size\n",
    "    step_size = step_size * dir_mag\n",
    "    \n",
    "    return Phi_next, Psi_next, dir_X_next, dir_Y_next, grad_X_next, \\\n",
    "        grad_Y_next, step_size, f_val_next, iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33702c6b",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca138427",
   "metadata": {},
   "source": [
    "### Optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of CG algorithm\n",
    "init_step_size = 1.0e-2\n",
    "\n",
    "ls_params = {'max_iter':20, 'c1':0.01, 'c2':0.1, 'fd_step':1.0e-8}\n",
    "\n",
    "step_size = init_step_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9bcb55",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f411287",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi, _, _ = sp.linalg.qr(Phi_cbal, pivoting=True, mode='economic')\n",
    "Psi, _, _ = sp.linalg.qr(Psi_cbal, pivoting=True, mode='economic')\n",
    "\n",
    "s, _ = np.linalg.slogdet(np.dot(Psi.T, Phi))\n",
    "Phi[:,0] = s*Phi[:,0]\n",
    "\n",
    "Phi_init = np.copy(Phi)\n",
    "Psi_init = np.copy(Psi)\n",
    "\n",
    "# initial cost, gradient, and search direction\n",
    "f_val, grad_Phi, grad_Psi = objective_grad(Phi, Psi)\n",
    "dir_Phi = -grad_Phi\n",
    "dir_Psi = -grad_Psi\n",
    "print(f_val)\n",
    "\n",
    "f_val_history = [f_val]\n",
    "\n",
    "grad_mag = np.sqrt(Grassmann_metric(grad_Phi, grad_Phi, Phi) + Grassmann_metric(grad_Psi, grad_Psi, Psi))\n",
    "print(grad_mag)\n",
    "\n",
    "grad_mag_history = [grad_mag]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db929e8",
   "metadata": {},
   "source": [
    "### Conjugate gradient iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24929f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_diff = np.inf\n",
    "iter = 0\n",
    "#while f_diff > 1.0e-12 and iter < 10:\n",
    "continue_cond = True\n",
    "\n",
    "fname = 'data/TrOOP/tmp_TrOOP_iter{:d}.mat'.format(iter)\n",
    "data = {'Phi': Phi, \\\n",
    "        'Psi': Psi, \\\n",
    "        'f_val': f_val, \\\n",
    "        'grad_mag': grad_mag, \\\n",
    "        'grad_Phi': grad_Phi, \\\n",
    "        'grad_Psi': grad_Psi, \\\n",
    "        'dir_Phi': dir_Phi, \\\n",
    "        'dir_Psi': dir_Psi, \\\n",
    "        'f_val_history': f_val_history, \\\n",
    "        'grad_mag_history': grad_mag_history, \\\n",
    "        'ls_params': ls_params, \\\n",
    "        'iter': iter}\n",
    "        \n",
    "\n",
    "with open(fname, 'wb') as fh:\n",
    "   pickle.dump(data, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e116fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "continue_cond = True\n",
    "while iter < 500 and continue_cond:\n",
    "    \n",
    "    if step_size < 1.0e-10:\n",
    "        step_size = init_step_size\n",
    "    \n",
    "    Phi_next, Psi_next, dir_Phi_next, dir_Psi_next, grad_Phi_next, \\\n",
    "    grad_Psi_next, step_size, f_val_next, n_steps = cg_step(Phi, Psi, f_val, \\\n",
    "                                                    dir_Phi, dir_Psi, \\\n",
    "                                                    grad_Phi, grad_Psi, \\\n",
    "                                                    step_size, \\\n",
    "                                                    ls_params=ls_params)\n",
    "    Phi = Phi_next\n",
    "    Psi = Psi_next\n",
    "    dir_Phi = dir_Phi_next\n",
    "    dir_Psi = dir_Psi_next\n",
    "    grad_Phi = grad_Phi_next\n",
    "    grad_Psi = grad_Psi_next\n",
    "    \n",
    "    grad_mag = np.sqrt(Grassmann_metric(grad_Phi, grad_Phi, Phi) + \\\n",
    "                       Grassmann_metric(grad_Psi, grad_Psi, Psi))\n",
    "    \n",
    "    continue_cond = grad_mag > 1.0e-4\n",
    "    \n",
    "    print('step {:d} cost {:.3e} grad mag {:.3e} step size {:.3e} LS iters {:d} \\n'.format(iter+1, \\\n",
    "                                                                                           f_val_next, \\\n",
    "                                                                                           grad_mag, \\\n",
    "                                                                                           step_size, \\\n",
    "                                                                                           n_steps))\n",
    "    f_diff = f_val - f_val_next\n",
    "    f_val = f_val_next\n",
    "    \n",
    "    f_val_history = f_val_history + [f_val]\n",
    "    grad_mag_history = grad_mag_history + [grad_mag]\n",
    "    \n",
    "    ## save progress\n",
    "    if iter % 1 == 0:\n",
    "        fname = 'data/TrOOP/POD_TrOOP_iter{:d}.mat'.format(iter)\n",
    "        data = {'Phi': Phi, \\\n",
    "                'Psi': Psi, \\\n",
    "                'f_val': f_val, \\\n",
    "                'grad_mag': grad_mag, \\\n",
    "                'grad_Phi': grad_Phi, \\\n",
    "                'grad_Psi': grad_Psi, \\\n",
    "                'dir_Phi': dir_Phi, \\\n",
    "                'dir_Psi': dir_Psi, \\\n",
    "                'f_val_history': f_val_history, \\\n",
    "                'grad_mag_history': grad_mag_history, \\\n",
    "                'ls_params': ls_params, \\\n",
    "                'iter': iter}\n",
    "        \n",
    "        with open(fname, 'wb') as fh:\n",
    "           pickle.dump(data, fh)\n",
    "    \n",
    "    iter = iter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa5d68",
   "metadata": {},
   "source": [
    "## TrOOP ROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/TrOOP/cbal_TrOOP_iter{:d}.mat'.format(499)\n",
    "\n",
    "with open(fname, 'rb') as fh:\n",
    "   data = pickle.load(fh)\n",
    "\n",
    "Phi = data['Phi']\n",
    "Psi = data['Psi']\n",
    "f_val = data['f_val']\n",
    "grad_mag = data['grad_mag']\n",
    "grad_Phi = data['grad_Phi']\n",
    "grad_Psi = data['grad_Psi']\n",
    "dir_Phi = data['dir_Phi']\n",
    "dir_Psi = data['dir_Psi']\n",
    "f_val_history = data['f_val_history']\n",
    "grad_mag_history = data['grad_mag_history']\n",
    "iter = data['iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/TrOOP/POD_TrOOP_iter{:d}.mat'.format(499)\n",
    "\n",
    "with open(fname, 'rb') as fh:\n",
    "   data = pickle.load(fh)\n",
    "\n",
    "f_val_history_POD = data['f_val_history']\n",
    "grad_mag_history_POD = data['grad_mag_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 4))\n",
    "plt.figure()\n",
    "plt.loglog(np.arange(len(f_val_history))+1, f_val_history, color='#1f78b4', linestyle='-', label='CoBRAS init.')\n",
    "plt.loglog(np.arange(len(f_val_history_POD))+1, f_val_history_POD, color='#b2df8a', linestyle='--', label='POD init.')\n",
    "\n",
    "plt.ylim([0.1, 50])\n",
    "\n",
    "# plt.grid(True, which='both')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# plt.savefig('../figures/jet_flow/TrOOP_cost_POD_vs_CoBRAS_init.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('../figures/jet_flow/TrOOP_cost_POD_vs_CoBRAS_init.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(8, 4))\n",
    "plt.figure()\n",
    "plt.loglog(np.arange(len(grad_mag_history))+1, grad_mag_history, color='#1f78b4', linestyle='-', label='CoBRAS init.')\n",
    "plt.loglog(np.arange(len(grad_mag_history_POD))+1, grad_mag_history_POD, color='#b2df8a', linestyle='--', label='POD init.')\n",
    "\n",
    "#plt.ylim([0.1, 50])\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# plt.savefig('../figures/jet_flow/TrOOP_grad_POD_vs_CoBRAS_init.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('../figures/jet_flow/TrOOP_grad_POD_vs_CoBRAS_init.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi-orthogonalize the matrix representatives\n",
    "Phi_TrOOP = np.copy(Phi)\n",
    "Psi_TrOOP = np.linalg.solve(np.dot(Psi.T, Phi), Psi.T).T\n",
    "\n",
    "# construct reduced-order model\n",
    "f0_TrOOP, A_TrOOP, B_TrOOP, C_TrOOP, H_TrOOP, N_TrOOP = assemble_rom(jet,lops, Phi_TrOOP, Psi_TrOOP)\n",
    "\n",
    "def TrOOP_ROM(z, u):\n",
    "    # nonlinearity\n",
    "    fN = np.einsum('ijk,j,k', H_TrOOP, z, z)\n",
    "    return f0_TrOOP + np.dot(A_TrOOP, z) + fN + np.dot(B_TrOOP, u)\n",
    "\n",
    "def TrOOP_ROM_Jac(z, u):\n",
    "    J = A_TrOOP + \\\n",
    "        np.einsum('ijk, k', H_TrOOP, z) + \\\n",
    "        np.einsum('ijk, j', H_TrOOP, z)\n",
    "    \n",
    "    return J\n",
    "\n",
    "def TrOOP_ROM_obs(z):\n",
    "    return np.dot(C_TrOOP, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be470be",
   "metadata": {},
   "source": [
    "## Trajectory predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7aa057",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict trajectory\n",
    "\n",
    "n_traj = len(alphas)\n",
    "z_TrOOP_pred = np.inf*np.ones((n_traj, A_TrOOP.shape[0], len(t_data)))\n",
    "for k in range(n_traj):\n",
    "    # simulate the ROM trajectory\n",
    "    u = sp.interpolate.interp1d(time, u_traj[k,:,:], axis=1)\n",
    "    z0 = B_TrOOP[:,0]*alphas[k]\n",
    "    sol = sp.integrate.solve_ivp(lambda t,z: TrOOP_ROM(z, u(t)), \\\n",
    "                                 jac = lambda t,z: TrOOP_ROM_Jac(z, u(t)), \\\n",
    "                                 t_span = [t_data[0], t_data[-1]], \\\n",
    "                                 y0 = z0, \\\n",
    "                                 t_eval = t_data, \\\n",
    "                                 method = 'BDF')\n",
    "    \n",
    "    z_TrOOP_pred[k,:,:sol.y.shape[1]] = sol.y\n",
    "\n",
    "## compute error\n",
    "gt_energy = np.mean(np.square(np.linalg.norm(x_traj_data, axis=1)), axis=1)\n",
    "\n",
    "TrOOP_sq_errors = np.square(np.linalg.norm(np.einsum('ijl,kj', z_TrOOP_pred, Phi_TrOOP) - x_traj_data, axis=1)) / \\\n",
    "                    np.reshape(gt_energy, (-1,1))\n",
    "\n",
    "TrOOP_energy = np.square(np.linalg.norm(np.einsum('ijl,kj', z_TrOOP_pred, Phi_TrOOP), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "k=0\n",
    "ax1.semilogy(t_data, TrOOP_sq_errors[k,:], color='#33a02c', linestyle='-', label='TrOOP')\n",
    "for k in range(1, n_traj):\n",
    "    ax1.semilogy(t_data, TrOOP_sq_errors[k,:], color='#33a02c', linestyle='-')\n",
    "\n",
    "ax1.set_ylabel('normalized square error')\n",
    "\n",
    "ax1.set_xlabel('t')\n",
    "\n",
    "#axs[1].set_yticks([])\n",
    "\n",
    "# ax1.set_xticks(np.arange(6))\n",
    "\n",
    "ax1.set_ylim([1.0e-3, 1.0e2])\n",
    "\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# plt.savefig('figures/toy_model/test_data_normalized_sqaure_error.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('figures/toy_model/test_data_normalized_sqaure_error.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd8c90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "705ed80f",
   "metadata": {},
   "source": [
    "# Compare Galerkin predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43695747",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "k=0\n",
    "ax1.semilogy(t_data, cbal_sq_errors[k,:], color='#1f78b4', linestyle='-', label='CoBRAS')\n",
    "ax1.semilogy(t_data, TrOOP_sq_errors[k,:], color='#33a02c', linestyle='-', label='TrOOP')\n",
    "ax1.semilogy(t_data, POD_sq_errors[k,:], color='#b2df8a', linestyle='--', label='POD')\n",
    "ax1.semilogy(t_data, BPOD_sq_errors[k,:], color='#a6cee3', linestyle=':', label='BPOD')\n",
    "for k in range(1, n_traj):\n",
    "    ax1.semilogy(t_data, cbal_sq_errors[k,:], color='#1f78b4', linestyle='-')\n",
    "    ax1.semilogy(t_data, TrOOP_sq_errors[k,:], color='#33a02c', linestyle='-')\n",
    "    ax1.semilogy(t_data, POD_sq_errors[k,:], color='#b2df8a', linestyle='--')\n",
    "    ax1.semilogy(t_data, BPOD_sq_errors[k,:], color='#a6cee3', linestyle=':')\n",
    "\n",
    "# ax1.set_ylabel('normalized square error')\n",
    "\n",
    "# ax1.set_xlabel('t')\n",
    "\n",
    "#axs[1].set_yticks([])\n",
    "\n",
    "# ax1.set_xticks(np.arange(6))\n",
    "\n",
    "ax1.set_ylim([1.0e-3, 1.0e2])\n",
    "\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "# plt.savefig('../figures/jet_flow/test_data_normalized_square_error.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('../figures/jet_flow/test_data_normalized_square_error.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_idx = 10\n",
    "print(t_data[t_idx])\n",
    "traj_idx = np.argmax(gt_energy)\n",
    "# traj_idx = np.argsort(gt_energy)[n_traj//2]\n",
    "# traj_idx = np.random.randint(n_traj)\n",
    "\n",
    "# print(alphas[traj_idx])\n",
    "\n",
    "flowfield_gt = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot(x_traj_data[traj_idx,:,t_idx]))) + q_sbf\n",
    "flowfield_cbal = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot( np.dot(Phi_cbal,z_cbal_pred[traj_idx,:,t_idx]) ))) + q_sbf\n",
    "flowfield_TrOOP = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot( np.dot(Phi_TrOOP,z_TrOOP_pred[traj_idx,:,t_idx]) ))) + q_sbf\n",
    "flowfield_POD = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot( np.dot(Phi_POD,z_POD_pred[traj_idx,:,t_idx]) ))) + q_sbf\n",
    "flowfield_BPOD = lops.BC_op.dot(lops.Wsqrtinv.dot(lops.Mapp.dot( np.dot(Phi_BPOD,z_BPOD_pred[traj_idx,:,t_idx]) ))) + q_sbf\n",
    "\n",
    "_, _, w_gt, Z, R = output_fields(jet,flowfield_gt)\n",
    "_, _, w_cbal, _, _ = output_fields(jet,flowfield_cbal)\n",
    "_, _, w_TrOOP, _, _ = output_fields(jet,flowfield_TrOOP)\n",
    "_, _, w_POD, _, _ = output_fields(jet,flowfield_POD)\n",
    "_, _, w_BPOD, _, _ = output_fields(jet,flowfield_BPOD)\n",
    "\n",
    "\n",
    "vminval = 0.0\n",
    "vmaxval = 10.0\n",
    "color_map = 'hot_r'\n",
    "\n",
    "fig, axs = plt.subplots(nrows=5, ncols=1, sharex=True)\n",
    "\n",
    "c=axs[0].contourf(Z,R,w_gt,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "axs[1].contourf(Z,R,w_cbal,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "axs[2].contourf(Z,R,w_TrOOP,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "axs[3].contourf(Z,R,w_POD,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "axs[4].contourf(Z,R,w_BPOD,levels=200,cmap=color_map,vmin=vminval,vmax=vmaxval)\n",
    "\n",
    "axs[0].set_aspect(1)\n",
    "axs[1].set_aspect(1)\n",
    "axs[2].set_aspect(1)\n",
    "axs[3].set_aspect(1)\n",
    "axs[4].set_aspect(1)\n",
    "\n",
    "axs[0].set_ylim([0,1.5])\n",
    "axs[1].set_ylim([0,1.5])\n",
    "axs[2].set_ylim([0,1.5])\n",
    "axs[3].set_ylim([0,1.5])\n",
    "axs[4].set_ylim([0,1.5])\n",
    "\n",
    "axs[0].set_title('t = {:.2f}, alpha = {:.4f}'.format(t_data[t_idx], alphas[traj_idx]))\n",
    "# axs[0].set_title('ground truth')\n",
    "# axs[1].set_title('SGBPOD')\n",
    "# axs[2].set_title('POD')\n",
    "# axs[3].set_title('BPOD')\n",
    "\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(c, cax=cbar_ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.savefig('../figures/jet_flow/snapshot_preds_t5_Emax.png', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)\n",
    "# plt.savefig('../figures/jet_flow/snapshot_preds_t5_Emax.eps', dpi=None, facecolor='w', edgecolor='w', \\\n",
    "#             transparent=False, bbox_inches=None, pad_inches=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
